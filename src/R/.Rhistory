available_tags("highway")
library(remotes)
remotes::install_github("ropensci/osmdata")
library(tidyverse)
library(osmdata) # package for working with streets
library(showtext) # for custom fonts
library(ggmap)
library(rvest)
available_tags("highway")
getbb("Atlanta Georgia")
big_streets <- getbb("Asheville United States")%>%
opq()%>%
add_osm_feature(key = "highway",
value = c("motorway", "primary", "motorway_link", "primary_link")) %>%
osmdata_sf()
big_streets
View(big_streets[["osm_lines"]])
library(dplyr)
library(readr)
library(srvyr)
library(survey)
library(ggplot2)
library(survey)
library(purrr)
library(stringr)
library(tidyr)
b1 = read_csv("~/github/masc_faces/emojis_analysis/mturk_results_batch1.csv")
b2 = read_csv("~/github/masc_faces/emojis_analysis/mturk_results_batch2.csv")
# Modify the single column in second batch about adult representation
b2mod = b2[, names(b2)[!names(b2) %in% names(b1)]] %>%
setNames(tolower(gsub("Answer.","",names(.)))) %>%
mutate(represents_adults = case_when(acceptable.a ~ "Acceptable",
excellent.e ~ "Excellent",
good.g ~ "Good",
poor.p ~ "Poor",
verygood.vg ~ "Very Good")) %>%
select(represents_adults)
# Create this variable for each batch
b1$Answer.represents_adults = NA
b2$Answer.represents_adults = b2mod$represents_adults
### Get the common values across the datasets and CONCATENATE
df = rbind(b1[, names(b1) %in% names(b2)], b2[, names(b2) %in% names(b1)])
df = df %>%
select(starts_with("Answer")) %>% # grab answers
setNames(tolower(gsub("Answer","",names(.)))) %>%
setNames(tolower(gsub("\\s|\\.|_","",names(.)))) %>%
mutate(competent = case_when(verycompetentverycompetent ~ "Very Competent",
competentcompetent ~ "Competent",
neitherneithercompetentnorincompetent ~ "Neither",
incompetentincompetent ~ "Incompetent",
veryincompetentveryincompetent ~ "Very Incompetent")) %>%
mutate(emoji_gender = case_when(ewomanw ~ "Woman",
emanm ~ "Man",
eneithern ~ "Neither")) %>%
mutate(respondent_gender = case_when(rwomanw ~ "Woman",
rmanm ~ "Man",
rneithern ~ "Neither",
rdkdk ~ "DK")) %>%
mutate(condition = case_when(experimentcondition == "https://emojis-bucket.s3.amazonaws.com/mshrug.png" ~ "Man",
experimentcondition == "https://emojis-bucket.s3.amazonaws.com/wshrug.png" ~ "Woman",
experimentcondition == "https://emojis-bucket.s3.amazonaws.com/nshrug.png" ~ "Neither")) %>%
mutate(attractive = howmuch) %>%
select(condition, respondent_gender, emoji_gender, competent, representsadults, attractive)
# Refactor levels
df$represents_adults = factor(df$representsadults, levels=
c("Poor", "Acceptable", "Good", "Very Good", "Excellent"))
df$looks_competent = factor(df$competent, levels =
c("Very Competent",
"Competent",
"Neither",
"Incompetent",
"Very Incompetent"))
df$competent_numeric = -1*as.numeric(df$looks_competent) + 3
# DESCRIPTIVES
### PROPORTIONS IDENTIFYING EMOJIS AS MEN, WOMEN, NEITHER
out = df %>%
as_survey_design(ids = 1) %>%
group_by(condition, emoji_gender) %>%
summarize(proportion = survey_mean(),
total = survey_total()) %>%
na.omit()
out
out[order(out$emoji_gender), ]
out
library(dplyr)
library(readr)
library(srvyr)
library(survey)
library(ggplot2)
library(survey)
library(purrr)
library(stringr)
library(tidyr)
b1 = read_csv("~/github/masc_faces/emojis_analysis/mturk_results_batch1.csv")
b2 = read_csv("~/github/masc_faces/emojis_analysis/mturk_results_batch2.csv")
# Modify the single column in second batch about adult representation
b2mod = b2[, names(b2)[!names(b2) %in% names(b1)]] %>%
setNames(tolower(gsub("Answer.","",names(.)))) %>%
mutate(represents_adults = case_when(acceptable.a ~ "Acceptable",
excellent.e ~ "Excellent",
good.g ~ "Good",
poor.p ~ "Poor",
verygood.vg ~ "Very Good")) %>%
select(represents_adults)
# Create this variable for each batch
b1$Answer.represents_adults = NA
b2$Answer.represents_adults = b2mod$represents_adults
### Get the common values across the datasets and CONCATENATE
df = rbind(b1[, names(b1) %in% names(b2)], b2[, names(b2) %in% names(b1)])
df = df %>%
select(starts_with("Answer")) %>% # grab answers
setNames(tolower(gsub("Answer","",names(.)))) %>%
setNames(tolower(gsub("\\s|\\.|_","",names(.)))) %>%
mutate(competent = case_when(verycompetentverycompetent ~ "Very Competent",
competentcompetent ~ "Competent",
neitherneithercompetentnorincompetent ~ "Neither",
incompetentincompetent ~ "Incompetent",
veryincompetentveryincompetent ~ "Very Incompetent")) %>%
mutate(emoji_gender = case_when(ewomanw ~ "Woman",
emanm ~ "Man",
eneithern ~ "Neither")) %>%
mutate(respondent_gender = case_when(rwomanw ~ "Woman",
rmanm ~ "Man",
rneithern ~ "Neither",
rdkdk ~ "DK")) %>%
mutate(condition = case_when(experimentcondition == "https://emojis-bucket.s3.amazonaws.com/mshrug.png" ~ "Man",
experimentcondition == "https://emojis-bucket.s3.amazonaws.com/wshrug.png" ~ "Woman",
experimentcondition == "https://emojis-bucket.s3.amazonaws.com/nshrug.png" ~ "Neither")) %>%
mutate(attractive = howmuch) %>%
select(condition, respondent_gender, emoji_gender, competent, representsadults, attractive)
# Refactor levels
df$represents_adults = factor(df$representsadults, levels=
c("Poor", "Acceptable", "Good", "Very Good", "Excellent"))
df$looks_competent = factor(df$competent, levels =
c("Very Competent",
"Competent",
"Neither",
"Incompetent",
"Very Incompetent"))
df$competent_numeric = -1*as.numeric(df$looks_competent) + 3
# DESCRIPTIVES
### PROPORTIONS IDENTIFYING EMOJIS AS MEN, WOMEN, NEITHER
out = df %>%
as_survey_design(ids = 1) %>%
group_by(condition, emoji_gender) %>%
summarize(proportion = survey_mean(),
total = survey_total()) %>%
na.omit()
# PLOT
p <- ggplot(data = out, aes(x=emoji_gender, y=proportion, col=condition)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() + ggtitle("Coder evaluations of gender expression")
p
ggplot(data = out, aes(x=emoji_gender, y=proportion, col=condition)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder evaluations of gender expression") +
ylab("Emoji Gender") + xlab("Proportion Responding")
ggplot(data = out, aes(x=emoji_gender, y=proportion, col=condition)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder Evaluations of Gender Expression") +
ylab("Emoji Gender") + xlab("Proportion Responding")
table(df$respondent_gender)
table(df$respondent_gender)/nrow(df)
lm(competent_numeric ~ looks_gender_neutral, data=mdf)
mdf = df %>%
dplyr::select(competent_numeric, condition, emoji_gender, attractive) %>%
na.omit() %>%
mutate(looks_gender_neutral = 1*(emoji_gender == "Neither")) %>%
mutate(is_gender_neutral = 1*(condition=="Neither"))
mdf
lm(competent_numeric ~ looks_gender_neutral, data=mdf)
summary(lm(competent_numeric ~ looks_gender_neutral, data=mdf))
mdf
p
p <- ggplot(data = out, aes(x=emoji_gender, y=proportion, col=condition)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder Evaluations of Gender Expression") +
ylab("Emoji Gender") + xlab("Proportion Responding")
p
p <- ggplot(data = out, aes(x=emoji_gender, y=proportion, col=condition)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder Evaluations of Gender Expression") +
xlab("Emoji Gender") + ylab("Proportion Responding")
p
library(texreg)
install.packages("texreg")
out = df %>%
as_survey_design(ids = 1) %>%
group_by(emoji_gender, competent) %>%
summarize(proportion = survey_mean(),
total = survey_total()) %>%
na.omit()
out
p <- ggplot(data = out, aes(x=competent, y=proportion, col=emoji_gender)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() + ggtitle("Coder evaluations of gender expression")
p
p <- ggplot(data = out, aes(x=competent, y=proportion, col=emoji_gender)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder Evaluations of Competence") + ylab("Proportion Responding") +
xlab("Evaluation")
p
df$looks_competent = factor(df$competent, levels =
c("Very Competent",
"Competent",
"Neither",
"Incompetent",
"Very Incompetent"))
p <- ggplot(data = out, aes(x=competent, y=proportion, col=emoji_gender)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder Evaluations of Competence") + ylab("Proportion Responding") +
xlab("Evaluation")
p
out = df %>%
as_survey_design(ids = 1) %>%
group_by(emoji_gender, looks_competent) %>%
summarize(proportion = survey_mean(),
total = survey_total()) %>%
na.omit()
# PLOT
p <- ggplot(data = out, aes(x=looks_competent, y=proportion, col=emoji_gender)) +
geom_point(position=position_dodge(.4)) +
geom_errorbar(aes(ymin=proportion-proportion_se*2, ymax=proportion+proportion_se*2), width=.2,
position=position_dodge(.4)) + theme_minimal() + coord_flip() +
ggtitle("Coder Evaluations of Competence") + ylab("Proportion Responding") +
xlab("Evaluation")
p
library(texreg)
mod_competence_main = lm(competent_numeric ~ looks_gender_neutral, data=mdf)
texreg(mod_competence_main)
#  Attractiveness and Gender Neutrality Combined
mod_competence_control = lm(competent_numeric ~ attractive + looks_gender_neutral, data=mdf)
texreg(mod_competence_control)
install.packages("babynames")
library(babynames)
babynames
library(dplyr)
babynames %>% filter(year < 1990, sex=="M")
babynames %>% filter(year < 1990, sex=="M")
?top_n
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .05)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .02)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .01)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .0001)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop < .0001)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .0001)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .000001)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > .0000000001)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(prop > 0)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(5)
babynames %>% filter(year < 1990, sex=="M") %>% top_n(50)
?distinct
hi = babynames %>% filter(year < 1990, sex=="M") %>% top_n(50)
View(hi)
hi = babynames %>% filter(year < 1990, sex=="M") %>% top_n(50, n)
hi
hi = babynames %>% filter(year < 1990, sex=="M") %>% top_n(50, prop)
hi
hi = babynames %>% filter(year < 1990, sex=="M") %>% top_n(50, n)
hi
hi = babynames %>% filter(sex=="M") %>% group_by(name) %>% summarize(total= sum(n)) %>% top_n(50, tota)
hi = babynames %>% filter(sex=="M") %>% group_by(name) %>% summarize(total= sum(n)) %>% top_n(50, total)
hi = babynames %>% filter(sex=="M") %>% group_by(name) %>% summarize(total= sum(n)) %>% top_n(-50, total)
this = babynames %>% filter(sex=="M", name=="Soren")
View(this)
library(ggplot2)
qplot(this$year, this$prop)
install.packages("rgdal")
library(rgdal)
?readOGR
dat = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb")
ogrListLayers("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb")
dat = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", "")
dat = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb")
dat = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", require_geomType="wkbPoint")
dat = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", require_geomType="wkbPolygon")
warnings()
ogrListLayers("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb")
dat = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", require_geomType="wkbPolygon", layer = "V700_WisconsinParcels_2021")
ogrDrivers()
ogrListLayers("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", layer = "V700_WisconsinParcels_2021")
ogrInfo("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", layer = "V700_WisconsinParcels_2021")
ogrInfo("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", layer = "V700_WisconsinParcels_2021", require_geomType="wkbPolygon")
hi = readOGR("~/Desktop/V7.0.0_Wisconsin_Parcels_2021_10.3_Uncompressed/V7.0.0_WISCONSIN_PARCELS_2021_10.3_Uncompressed.gdb", layer = "V700_WisconsinParcels_2021", require_geomType="wkbPolygon")
library(rgdal)
?readOGR
ogrDrivers()
load("~/Desktop/DC house price analysis/plot_dc.RData")
library(remotes)
library(tidyverse)
library(osmdata) # package for working with streets
library(showtext) # for custom fonts
library(ggmap)
library(rvest)
map_plot_data = ggplot() +
geom_sf(data = river$osm_lines,
inherit.aes = FALSE,
color = "steelblue",
size = .8,
alpha = .3) +
geom_sf(data = railway$osm_lines,
inherit.aes = FALSE,
color = "black",
size = .2,
linetype="dotdash",
alpha = .5) +
geom_sf(data = med_streets$osm_lines,
inherit.aes = FALSE,
color = "black",
size = .3,
alpha = .5) +
geom_sf(data = small_streets$osm_lines,
inherit.aes = FALSE,
color = "#666666",
size = .2,
alpha = .3) +
geom_sf(data = big_streets$osm_lines,
inherit.aes = FALSE,
color = "black",
size = .5,
alpha = .6) +
coord_sf(xlim = c(-77.05, -76.95),
ylim = c(38.85, 38.95),
expand = FALSE) + theme_void() + # get rid of background color, grid lines, etc.
theme(plot.title = element_text(size = 20, family = "lato", face="bold", hjust=.5),
plot.subtitle = element_text(family = "lato", size = 8, hjust=.5, margin=margin(2, 0, 5, 0))) +
labs(title = "DC", subtitle = "38.90°N / 77.00°W")
map_plot_data + geom_point(data=df, aes(x=latLong.value.longitude,y=latLong.value.latitude), col="red", alpha=.2)
shiny::runApp('github/wisgeo/src/R/DearestNeighbors')
update.packages("htmltools")
library(htmltools)
shiny::runApp('github/wisgeo/src/R/DearestNeighbors')
parcels = read_csv("~/github/wisgeo/data/Wisconsin_Parcels_2021V7.csv")
library(readr)
parcels = read_csv("~/github/wisgeo/data/Wisconsin_Parcels_2021V7.csv")
runApp('github/wisgeo/src/R/DearestNeighbors')
head(parcels$ESTFMKVALUE)
parcels = parcels %>% drop_na(ESTFMKVALUE)
library(tidyr)
parcels = parcels %>% drop_na(ESTFMKVALUE)
runApp('github/wisgeo/src/R/DearestNeighbors')
runApp('github/wisgeo/src/R/DearestNeighbors')
runApp('github/wisgeo/src/R/DearestNeighbors')
summary(log(parcels$ESTFMKVALUE))
summary(log(parcels$ESTFMKVALUE + 1))
runApp('github/wisgeo/src/R/DearestNeighbors')
runApp('github/wisgeo/src/R/DearestNeighbors')
runApp('github/wisgeo/src/R/DearestNeighbors')
runApp('github/wisgeo/src/R/DearestNeighbors')
library(dplyr)
library(stringr)
library(readr)
library(lubridate)
library(tidyr)
library(stringr)
library(fuzzyjoin)
#LOAD THE FULL PARCELS SET
out = read_csv("../../data/Wisconsin_Parcels_2021V7.csv")%>%
mutate(MYPARCELID = TAXPARCELID)
setwd("~/github/wisgeo/src/R")
#LOAD THE FULL PARCELS SET
out = read_csv("../../data/Wisconsin_Parcels_2021V7.csv")%>%
mutate(MYPARCELID = TAXPARCELID)
sum(duplicated(out$MYPARCELID))
length(duplicated(out$MYPARCELID))
head(out$MYPARCELID)
ncols(out)
ncol(out)
head(out)
out = read_csv("../../data/Wisconsin_Parcels_2021V7.csv", col_types = "c")%>%
mutate(MYPARCELID = TAXPARCELID)
View(out)
class(out$STATE)
class(out$PARCELDATE)
class(out$PARCELID)
head(out)
?col_types
?read_csv
rep("c", 47)
out = read_csv("../../data/Wisconsin_Parcels_2021V7.csv", col_types = rep("c", 47))%>%
mutate(MYPARCELID = TAXPARCELID)
paste(rep("c", 47)), collapse="")
paste(rep("c", 47), collapse="")
paste(rep("c", 47), collapse="")
paste(rep("c", 47), collapse="")
out = read_csv("../../data/Wisconsin_Parcels_2021V7.csv", col_types = paste(rep("c", 47), collapse=""))%>%
mutate(MYPARCELID = TAXPARCELID)
apply(out, 2, function(x) class(x))
head(out)
out$MYPARCELID
out$MYPARCELID[which(is.na(out$MYPARCELID))] <- out$PARCELID[which(is.na(out$MYPARCELID))]
sum(is.na(out$MYPARCELID))
sum(!is.na(out$MYPARCELID))
?drop_na
out %>% drop_na(MYPARCELID)
out = out %>% drop_na(MYPARCELID)
length(unique(out$MYPARCELID))
length(unique(out$MYPARCELID))/nrow(out)
length(unique(duplicated(out$MYPARCELID)))
length(duplicated(out$MYPARCELID))
length(unique(duplicated(out$MYPARCELID)))
unique(duplicated(out$MYPARCELID))
sum(duplicated(out$MYPARCELID))
sum(!duplicated(out$MYPARCELID))
sum(duplicated(out$MYPARCELID))/nrow(out)
head(out[duplicated(out$MYPARCELID), ])
this= out[duplicated(out$MYPARCELID), ]
View(this)
table(this$PLACENAME)
table(this$PARCELSRC)
table(this$CONAME)
sum(is.na(this$PLACENAME))
sum(is.na(this$PLACENAME))/nrow(this)
sum(is.na(this$ZIPCODE))/nrow(this)
sum(is.na(this$STATE))/nrow(this)
sum(is.na(this$SITEADRESS))/nrow(this)
sum(duplicated(out$MYPARCELID))/nrow(out)
table(this$UNITID)
table(this$PROPCLASS)
sum(str_detect(PROPCLASS, "1"))
sum(str_detect(out$PROPCLASS, "1"))
sum(str_detect(out$PROPCLASS, "1"), na.rm=T)
sum(str_detect(this$PROPCLASS, "1"), na.rm=T)
sum(str_detect(this$PROPCLASS, "1"), na.rm=T)/nrow(this)
sum(str_detect(this$PROPCLASS, "5"), na.rm=T)/nrow(this)
dims(out[!duplicated(out$MYPARCELID), ])
dim(out[!duplicated(out$MYPARCELID), ])
table(this$PARCELDATE)
out= out[!duplicated(out$MYPARCELID), ]
trans = read_csv("../../data/alltransfers_2016to_2021.csv") %>%
filter(PredominateUse == 1 & PropertyType == 2 & OwnerInterestTransferred == 1 & TransferType == 1) %>%
mutate(PARCELID = str_replace_all(ParcelIdentification, "-", "")) %>%
mutate(PARCELID = str_replace(PARCELID, "PRCL", ""))
View(trans)
trans$myid = paste(trans$PARCELID, trans$CertificationDate)
sum(duplicated(trans$myid))
sum(!duplicated(trans$myid))
this = trans[duplicated(trans$id), ]# 8,670 duplicates
trans[which(duplicated(trans$id)), ]
trans[which(duplicated(trans$myid)), ]
this = trans[which(duplicated(trans$myid)), ]# 8,670 duplicates
View(this)
out = read_csv("../../data/Wisconsin_Parcels_2021V7.csv", col_types = paste(rep("c", 47), collapse=""))%>%
mutate(MYPARCELID = TAXPARCELID)
# MYPARCELID created hered
out$MYPARCELID[which(is.na(out$MYPARCELID))] <- out$PARCELID[which(is.na(out$MYPARCELID))]
out = out %>% drop_na(MYPARCELID)
####### LOOKING AT THE DUPLICATES
this= out[duplicated(out$MYPARCELID), ]
# some missing parcel iDs
sum(duplicated(out$MYPARCELID))/nrow(out)
# lots missing site addresses
sum(duplicated(out$MYPARCELID))/nrow(out)
# 37 % are residential properties
sum(str_detect(this$PROPCLASS, "1"), na.rm=T)/nrow(this)
# 25% are undeveloed land
sum(str_detect(this$PROPCLASS, "5"), na.rm=T)/nrow(this)
out= out[!duplicated(out$MYPARCELID), ]
out = out %>%
anti_join(this, by="MYPARCELID")
trans = trans %>%
anti_join(this, by = "myid")
trans = read_csv("../../data/alltransfers_2016to_2021.csv") %>%
filter(PredominateUse == 1 & PropertyType == 2 & OwnerInterestTransferred == 1 & TransferType == 1) %>%
mutate(PARCELID = str_replace_all(ParcelIdentification, "-", "")) %>%
mutate(PARCELID = str_replace(PARCELID, "PRCL", ""))
# Experimenting with unique ID's for the transfer data AND LOOKING AT DUPLICATES
trans$myid = paste(trans$PARCELID, trans$CertificationDate)
this = trans[which(duplicated(trans$myid)), ]# 8,670 duplicates
trans = trans %>%
anti_join(this, by = "myid")
head(trans$myid)
head(out$MYPARCELID)
head(trans$SplitParcel)
head(out$MYPARCELID, 10)
head(trans$myid)
hi = data.frame(myid=trans$myid, SplitParcel=trans$SplitParcel)
View(hi)
hi = trans %>%
left_join(out, on=c("myid" = "MYPARCELID"))
?left_join
hi = trans %>%
left_join(out, by=c("myid" = "MYPARCELID"))
sum(hi$CONAME)
View(hi)
head(hi$CONAME)
sum(is.na(hi$CONAME))
sum(!is.na(hi$CONAME))
?stringdist_left_join
names(trans)
View(trans)
head(trans$PropertyAddress)
head(out$SITEADRESS)
trans$addressid = paste(trans$PropertyAddress, trans$CountyName)
out$addressid = paste(out$SITEADRESS, out$CONAME)
hi = trans %>%
stringdist_left_join(out, by="addressid")
